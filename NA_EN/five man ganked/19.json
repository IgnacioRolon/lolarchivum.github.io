{"poster":"Five man ganked","date":"2014-12-02T06:54:32.475+0000","title":"Time to shame some Nvidia fanboys :)","subforum":"[ARCHIVED] General Discussion","up_votes":5,"down_votes":13,"body":"I was going to let the thread die, as it seemed that I did not have enough intelligent people to argue with, but then this %%%%%% came along.\n> I'm going to repost my post from your other thread which you are apparently afraid to look at because you got your owned due to your utter lack of knowledge on the topic.\n> \n> > Thermal and energy concerns the 980 beats AMD gpus, period. Now... your little picture...\n> > \n> > On passmark the R9 295x2 gets a score of 7,140 while the GTX 980 yields 9,708 along with 7 other GPUs beating that AMD card. http://www.videocardbenchmark.net/high_end_gpus.html\n> > \n> > You talk about the 390x beating an older mid range GPU (the 980 is NOT a high end solution) and act as if Nvidia won't be able to pump out a competitive card by its release... Do you realize just how much thermal/energy headroom the 900 series has? Just on this alone it can likely keep up with the 390x and this is assuming that the 390x is ready to launch at that time which is very iffy considering past silicon issues. Maxwell, at least, is already out and quite successful so far. What do you mean paying twice as much for less performance? The R9 295x2 that YOU are refering to, OP, is over $700 USD while the GTX 980 is sitting around the $600 USD mark and the GTX 970 (not too far off from the 980) and the GTX 780 both sit at mid and low $300 USD point. Lets not forget AMD isn't very good with drivers and often has to optimize code by directly working with developers while Nvidia handles this almost exclusively via driver updates with generally great drivers (don't believe me or want to argue do a little research on AMD against Gameworks).\n> > \n> > AMD's aren't really bad GPUs and often they have some pretty solid deals, but at the moment they are simply not a good choice. Why are you trying to talk crap about something you have little understanding about? Actual current performance values aside there is also the issue of Nvidia Gameworks such as PhysX, Hairworks, HBAO+, TXAA, and much more if utilizing an Nvidia GPU and we are starting to see more games utilize these technologies.\n> \n> ^quoting myself from other thread full of your nonsense. http://boards.na.leagueoflegends.com/en/c/GD/wZUwvw3W-nvidia-is-soooo-much-better-than-amd-the-980-is-godlike?show=flat&amp;page=4\n\nNow see folks, I want to single handedly show you a person that would spout misinformation just to win an internet argument. And I am going to bust every single \"point\" he makes. This is by far the worst I have seen someone spread lies over the internet, and everybody needs to remember this persons name.\n\nSo let's get started!\n\n> > Thermal and energy concerns the 980 beats AMD gpus, period. Now... your little picture...\n\nThe first sentence he has in his original post, he is already making a false statement claiming that the Liquid cooled 295x2 runs hotter than the GTX 980. So  let's do some digging.\n\nhttp://i.gyazo.com/ca6b8210ff463f8c953d0d1ec01aa52b.png\nhttp://i.gyazo.com/d715d3fb390272dcc9fa28a0c13a1f19.png\n\nThis set of images is provided from guru3d and this shows the card's temps at idle. As you can see the 295x2 is indeed cooler here.\n\nhttp://i.gyazo.com/340b94f256ab3e3f073c1b4e5abca760.png\nhttp://i.gyazo.com/58fc7c97cea04d52255631d9f6f36cee.png\n\nAnd here we have 100% utilization, and you can see that the 295x2 is cooler again.\n\n\"But this isn't a fair comparison! The 295x2 is liquid cooled!\" Nvidia fanboys cry.\n\nActually this is completely fair, as these are both the stock reference coolers provided by both AMD and Nvidia. AMD decided to include the liquid cooler into the 295x2 for the same price.\n\n> > On passmark the R9 295x2 gets a score of 7,140 while the GTX 980 yields 9,708 along with 7 other GPUs beating that AMD card. http://www.videocardbenchmark.net/high_end_gpus.html\n\nWow, this is some great detective work! It is funny though that you are comparing a dual GPU card to a single GPU card in a single GPU benchmark. Passmark does not utilize the second GPU at all. Do you want to know how I know this? Look here:\nhttp://i.gyazo.com/ac4d2d381c3a35517f04c15d2bd38a0a.png\n\nThis is the top 10 graphics cards on Passmark. Notice how the Titan beats out the Titan Z (The dual GPU Titan), and the single 290x barely losses to the 295x2 (The OC'd Dual GPU 290x).\n\nLet's look at some valid benchmarks:\nhttp://i.gyazo.com/649c32924d8989407a1cc65feb0c24bb.png\nhttp://i.gyazo.com/b7fb90625cbaa0c1b9fbb12d5bb3cf6f.png\nhttp://i.gyazo.com/1e0c222808a24104953a563b628b9138.png\n\nI think these are enough for you to get the picture, but if you think any of this pictures are bogus... go look for yourself.\n\n> > You talk about the 390x beating an older mid range GPU (the 980 is NOT a high end solution) and act as if Nvidia won't be able to pump out a competitive card by its release... Do you realize just how much thermal/energy headroom the 900 series has?\n\nThe 295x2 is an older card, and it is for the same price point, so if Nvidia already is losing to AMD's last generation, why do you think they will be able to beat the 390x? Have you seen Nvidia's response to the 295x2, the Titan Z?\n\n>The R9 295x2 that YOU are refering to, OP, is over $700 USD while the GTX 980 is sitting around the $600 USD mark and the GTX 970 (not too far off from the 980) and the GTX 780 both sit at mid and low $300 USD point. \n\nThe absolute cheapest corner cutting design of the 970 is $330. To get a quality 970 you would need to spend $350+. With the 295x2 you are getting an AMD reference design, so you know you are not getting ripped off of important components.\n\nDon't believe me? Once again, check for youself:\nhttp://www.newegg.com/Product/ProductList.aspx?Submit=ENE&amp;N=100007709&amp;IsNodeId=1&amp;Description=970%20gtx&amp;name=Desktop%20Graphics%20Cards&amp;Order=PRICE&amp;Pagesize=30&amp;isdeptsrh=1\n\nOn top of this, you are choosing to SLI two cards that have abysmal memory bandwidth, which defeats the purpose of getting such a high end setup for 4k.\n\n>Lets not forget AMD isn't very good with drivers and often has to optimize code by directly working with developers while Nvidia handles this almost exclusively via driver updates with generally great drivers (don't believe me or want to argue do a little research on AMD against Gameworks).\n\nAre you kidding me? You are saying Gameworks is a pro instead of a con? Gameworks is proof that Nvidia knows it's ass is getting kicked and they need to bring out monopolizing tactics to stay relevant.\nYou should really educate yourself on Gameworks, let me paste my old thread:\n>In an effort of Nvidia trying to manipulate the industry, they are killing PC gaming even for themselves.\n\n>Let me just some of the \"amazing\" performance games that Gameworks provides:\nAssassin's Creed Unity\nWATCH_DOGS\nCall of Duty: Ghosts\nAssassin's Creed IV: Blackflag\nBatman Arkham Origins\n\n\n>For people who don't know what Gameworks is. It is an SDK to add effects or rending technologies to \"optimize\" for Nvidia based GPUs, without having to properly add effects themselves like HBAO+. If this technology worked as Nvidia intended, it would only strangle AMD cards into resulting into poor performance. \n\n>The reality however, is in their effort to cheat their way out of producing better products (Like Intel and their compiler)... they actually fuck everybody over. There has not been a single Nvidia Gameworks game to date that has performed properly.  Just look at AW compared to Ghosts, the game runs on the same engine, but one is Gameworks enabled and one is not. Can you guess which one?\nhttp://i.imgur.com/gHSO9qP.png\nhttp://i.imgur.com/QOxbSjf.png\nhttp://i.imgur.com/2VWii0x.png\n\n>Please do not buy Gameworks enabled games, as it is poor practice for both GPU manufacturers and Game Developers.\n\nThe rest is not really anything to argue with, he's just restating false information.","replies":[]}